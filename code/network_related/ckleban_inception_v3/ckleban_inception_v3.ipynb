{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.gfile.FastGFile(os.path.join(\n",
    "    '../../../data/inception-2015-12-05/classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert own output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('own'):\n",
    "    y = tf.placeholder(\"float\")\n",
    "    x = g.get_tensor_by_name('pool_3/_reshape:0')\n",
    "    w = tf.Variable(tf.random_normal(\n",
    "        [int(x.get_shape()[-1]),300], stddev=0.1), name='weights')\n",
    "    b = tf.Variable(tf.random_normal([1,300]), name='bias')\n",
    "    y_pred = tf.add(tf.matmul(x, w), b, name='y_pred')\n",
    "    cost = tf.reduce_sum(tf.pow(y-y_pred, 2),name='cost')\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "    # Class prediction (not useful for us)\n",
    "    softmax_tensor = g.get_tensor_by_name('softmax:0')\n",
    "\n",
    "# Write to file in order to visualize graph in tensorflow\n",
    "sum_writer = tf.summary.FileWriter('./sums', g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Images\n",
    "image_path = '../../../data/val2014/'\n",
    "image_list = os.listdir(image_path)\n",
    "# Class labels\n",
    "labels_file = open('../../../data/imagenet_comp_graph_label_strings.txt', 'r')\n",
    "labels = labels_file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read captions (create own_dict for now, should be read from pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_caption(caption):\n",
    "    caption_splitted = re.split(\"[^a-zåàâäæçéèêëîïôöœßùûüÿA-ZÅÀÂÄÆÇÉÈÊËÎÏÔÖŒÙÛÜŸ’\\-]+\",caption)\n",
    "    caption_vector = np.array(300*[0])\n",
    "    for c in caption_splitted:\n",
    "        try:\n",
    "            caption_vector = caption_vector + w2v[c]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return tuple(caption_vector)\n",
    "\n",
    "w2v = Word2Vec.load_word2vec_format('../../../data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v.init_sims(replace=True)\n",
    "\n",
    "train_path = \"../../../data/annotations/captions_val2014.json\"\n",
    "with open(train_path, 'r') as train_file:\n",
    "    train_dict = json.load(train_file)\n",
    "\n",
    "own_dict = {}\n",
    "for im in train_dict[\"images\"]:\n",
    "    own_dict[im[\"id\"]] = {}\n",
    "    own_dict[im[\"id\"]][\"url\"] = im[\"flickr_url\"]\n",
    "    own_dict[im[\"id\"]][\"file_name\"] = im[\"file_name\"]\n",
    "for cap in train_dict[\"annotations\"]:\n",
    "    try:\n",
    "        own_dict[cap[\"image_id\"]][\"captions\"].append(cap[\"caption\"])\n",
    "        own_dict[cap[\"image_id\"]][\"vectors\"].append(sum_caption(cap[\"caption\"]))\n",
    "    except KeyError:\n",
    "        own_dict[cap[\"image_id\"]][\"captions\"] = [cap[\"caption\"]]\n",
    "        own_dict[cap[\"image_id\"]][\"vectors\"] = [sum_caption(cap[\"caption\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1873.42\n",
      "Airedale\n",
      "\n",
      "1142.48\n",
      "moped\n",
      "\n",
      "1658.32\n",
      "jinrikisha\n",
      "\n",
      "1961.72\n",
      "desk\n",
      "\n",
      "1420.88\n",
      "leopard\n",
      "\n",
      "1387.81\n",
      "home theater\n",
      "\n",
      "1170.09\n",
      "bulbul\n",
      "\n",
      "1866.77\n",
      "china cabinet\n",
      "\n",
      "1665.9\n",
      "ballplayer\n",
      "\n",
      "1493.6\n",
      "hot pot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run([w.initializer, b.initializer])\n",
    "    for im in image_list[:10]:\n",
    "        image = tf.gfile.FastGFile(image_path + im, 'rb').read()\n",
    "        image_id = re.findall('[1-9]+',re.findall('_([0-9]+)',image_list[0])[0])[0]\n",
    "        # Choose one of the five captions\n",
    "        r = random.randrange(len(own_dict[int(image_id)]['vectors']))\n",
    "        y_temp = np.asarray(own_dict[int(image_id)]['vectors'][r]).reshape((1,300))\n",
    "        # Calculate cost\n",
    "        print(sess.run(cost, {'DecodeJpeg/contents:0':image, y:y_temp}))\n",
    "        # Predict class\n",
    "        softmax_out = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image})\n",
    "        softmax_out = np.squeeze(softmax_out)\n",
    "        class_pred = np.argmax(softmax_out)\n",
    "        print(labels[class_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
