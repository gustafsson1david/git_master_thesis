{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gc\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.gfile.FastGFile(os.path.join(\n",
    "    '../../../data/inception-2015-12-05/classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create own branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('own'):\n",
    "    y = tf.placeholder(\"float\")\n",
    "    x = g.get_tensor_by_name('pool_3/_reshape:0')\n",
    "    x_batch = g.get_tensor_by_name(\"pool_3:0\")\n",
    "    w = tf.Variable(tf.random_normal(\n",
    "        [int(x.get_shape()[-1]),300], stddev=float('1e-5')), name='weights')\n",
    "    b = tf.Variable(tf.random_normal([1,300]), name='bias')\n",
    "    y_pred = tf.add(tf.matmul(x, w), b, name='y_pred')\n",
    "    cost = tf.reduce_sum(tf.square(y-y_pred),name='cost')\n",
    "    cost_summary = tf.summary.scalar('cost', cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=float('1e-5')).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "def mini_batch(sess, y_batch, im_batch, batch_size):\n",
    "#with tf.name_scope('batch'):\n",
    "    y_batch = tf.placeholder(\"float\", shape=(batch_size, 300))\n",
    "    im_batch = tf.placeholder(\"float\", shape=(batch_size, None, None, 3))\n",
    "    cost_batch = 0\n",
    "    for j in range(np.shape(y_batch)[0]):\n",
    "        temp_im = g.get_tensor_by_name('DecodeJpeg/contents:0')\n",
    "        temp_im = im_batch[j,:]\n",
    "        cost_batch += sess.run(cost,{'DecodeJpeg/contents:0':im_batch[j,:,:], y:y_batch[j,:]})\n",
    "    batch_optimizer = tf.train.GradientDescentOptimizer(learning_rate=float('1e-5')).minimize(cost_batch)\n",
    "    return batch_optimizer\n",
    "\n",
    "with tf.name_scope('try_values'):\n",
    "    xxx = g.get_tensor_by_name('DecodeJpeg/contents:0')\n",
    "    print(xxx, end='\\n\\n')\n",
    "    print(xxx.consumers())\n",
    "    yyy = g.get_tensor_by_name('DecodeJpeg/contents:0')\n",
    "    print(yyy)\n",
    "    print(xxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Images\n",
    "image_path = '../../../data/train2014/'\n",
    "image_list = os.listdir(image_path)\n",
    "# Caption dictionaries\n",
    "vec_dict = np.load('../../../data/word2vec_train.npy').item()\n",
    "with open('../../../data/caption_train.pkl', 'rb') as f:\n",
    "    string_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"own/weights/read:0\", shape=(2048, 300), dtype=float32)\n",
      "Tensor(\"own/bias/read:0\", shape=(1, 300), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2, 299, 299, 3) for Tensor 'ResizeBilinear:0', which has shape '(1, 299, 299, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7fadbfe65ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimage_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbatched_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'ResizeBilinear:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatched_images\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Choose one of the five captions randomly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    944\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (2, 299, 299, 3) for Tensor 'ResizeBilinear:0', which has shape '(1, 299, 299, 3)'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "with tf.Session(graph=g) as sess:\n",
    "#    # Initialize writers\n",
    "#    timestamp = time.strftime('%Y%m%d-%H%M', time.localtime())\n",
    "#    train_writer = tf.summary.FileWriter('./sums/train/'+timestamp, graph=g, flush_secs=20)\n",
    "#    test_writer = tf.summary.FileWriter('./sums/test/'+timestamp, graph=g, flush_secs=20)\n",
    "    \n",
    "    sess.run([w.initializer, b.initializer])\n",
    "    for i, im in enumerate(image_list[:500]):\n",
    "        # Tried to follow\n",
    "        # http://stackoverflow.com/questions/35274457/inceptionv3-and-transfer-learning-with-tensorflow/40709836#40709836\n",
    "        image_1 = np.array(Image.open(image_path + image_list[0]))\n",
    "        image_2 = np.array(Image.open(image_path + image_list[1]))\n",
    "        batched_images = np.stack((image_1[:299,:299,:],image_2[:299,:299,:]))\n",
    "        input(sess.run(x_batch, {'ResizeBilinear:0':batched_images}))\n",
    "        # Choose one of the five captions randomly\n",
    "        r = random.randrange(len(vec_dict[im]))\n",
    "        y_temp = vec_dict[im][r].reshape((1,300))\n",
    "\n",
    "        optimizer.run(feed_dict={'DecodeJpeg/contents:0':image, y:y_temp})\n",
    "        train_writer.add_summary(sess.run(cost_summary,{'DecodeJpeg/contents:0':image, y:y_temp}), i)\n",
    "        print(i, end=' ')\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            test_image = tf.gfile.FastGFile(image_path + image_list[-1], 'rb').read()\n",
    "            y_test = vec_dict[image_list[-1]][1].reshape((1,300))\n",
    "            test_writer.add_summary(sess.run(cost_summary,{'DecodeJpeg/contents:0':test_image, y:y_test}), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
