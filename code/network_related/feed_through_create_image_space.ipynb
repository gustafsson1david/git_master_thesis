{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.python.slim.nets.inception_v3 import inception_v3\n",
    "from tensorflow.contrib.slim.python.slim.nets.inception_v3 import inception_v3_arg_scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Preprocessing'):\n",
    "    input_im = tf.placeholder(tf.uint8, shape=[None, None, None, 3], name='input_im')\n",
    "    resized_im = tf.image.resize_bilinear(tf.image.convert_image_dtype(\n",
    "        tf.convert_to_tensor(input_im) ,dtype=tf.float32), [299,299], name='resized_im')\n",
    "    normalized_im = tf.mul(tf.sub(resized_im, 0.5), 2.0, name='normalized_im')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Inception-v3 graph from slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with slim.arg_scope(inception_v3_arg_scope()):\n",
    "    logits, end_points = inception_v3(normalized_im, num_classes=1001, is_training=False)\n",
    "slim_variables = [v for v in tf.global_variables() if v.name.startswith('InceptionV3/')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create own branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Own'):\n",
    "    y = tf.placeholder(\"float\")\n",
    "    x = tf.reshape(g.get_tensor_by_name('InceptionV3/Logits/SpatialSqueeze:0'),(1,1001))\n",
    "    w = tf.Variable(tf.random_normal([int(x.get_shape()[-1]),300], stddev=float('1e-5')), name='weights')\n",
    "    b = tf.Variable(tf.random_normal([1,300]), name='bias')\n",
    "    y_pred = tf.add(tf.matmul(x, w), b, name='y_pred')\n",
    "    cost = tf.reduce_sum(tf.square(y-y_pred),name='cost')\n",
    "    cost_summary = tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Images\n",
    "val_image_path = '../../data/val2014/'\n",
    "val_image_list = os.listdir(val_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 710 720 730 740 750 760 770 780 790 800 810 820 830 840 850 860 870 880 890 900 910 920 930 940 950 960 970 980 990 \n",
      "\n",
      "Image space saved to ../../data/image_space_20170213-1541.npy\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    timestamp = time.strftime('%Y%m%d-%H%M', time.localtime())\n",
    "    saver = tf.train.Saver()\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(\n",
    "        \"./slim_inception_v3/runs/20170213-1508/checkpoint/\")\n",
    "    saver.restore(sess, latest_checkpoint)\n",
    "    \n",
    "    # Single-threaded\n",
    "    new_vec_dict = {}\n",
    "    for i, im in enumerate(val_image_list[:1000]):\n",
    "        image = [np.array(Image.open(val_image_path + im))]\n",
    "        try:\n",
    "            new_vec_dict[im] = sess.run(y_pred,feed_dict={input_im:image})\n",
    "        except ValueError:\n",
    "            pass\n",
    "        if i % 10 == 0:\n",
    "            print(i, end=' ')\n",
    "    \n",
    "    save_path = '../../data/image_space_'+timestamp+'.npy'\n",
    "    np.save(save_path,new_vec_dict)\n",
    "    print('\\n\\nImage space saved to {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
