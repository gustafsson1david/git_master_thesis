{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "import functools\n",
    "\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "\n",
    "class Vgg19:\n",
    "    \"\"\"\n",
    "    A trainable version VGG19.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vgg19_npy_path=None, trainable=True):\n",
    "        if vgg19_npy_path is not None:\n",
    "            self.data_dict = np.load(vgg19_npy_path, encoding='latin1').item()\n",
    "        else:\n",
    "            self.data_dict = None\n",
    "\n",
    "        self.var_dict = {}\n",
    "        self.trainable = trainable\n",
    "\n",
    "    def build(self, rgb, train_mode=None):\n",
    "        \"\"\"\n",
    "        load variable from npy to build the VGG\n",
    "\n",
    "        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n",
    "        :param train_mode: a bool tensor, usually a placeholder: if True, dropout will be turned on\n",
    "        \"\"\"\n",
    "\n",
    "        rgb_scaled = rgb * 255.0\n",
    "\n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(3, 3, rgb_scaled)\n",
    "        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        bgr = tf.concat(3, [\n",
    "            blue - VGG_MEAN[0],\n",
    "            green - VGG_MEAN[1],\n",
    "            red - VGG_MEAN[2],\n",
    "        ])\n",
    "        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n",
    "\n",
    "        self.conv1_1 = self.conv_layer(bgr, 3, 64, \"conv1_1\")\n",
    "        self.conv1_2 = self.conv_layer(self.conv1_1, 64, 64, \"conv1_2\")\n",
    "        self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n",
    "\n",
    "        self.conv2_1 = self.conv_layer(self.pool1, 64, 128, \"conv2_1\")\n",
    "        self.conv2_2 = self.conv_layer(self.conv2_1, 128, 128, \"conv2_2\")\n",
    "        self.pool2 = self.max_pool(self.conv2_2, 'pool2')\n",
    "\n",
    "        self.conv3_1 = self.conv_layer(self.pool2, 128, 256, \"conv3_1\")\n",
    "        self.conv3_2 = self.conv_layer(self.conv3_1, 256, 256, \"conv3_2\")\n",
    "        self.conv3_3 = self.conv_layer(self.conv3_2, 256, 256, \"conv3_3\")\n",
    "        self.conv3_4 = self.conv_layer(self.conv3_3, 256, 256, \"conv3_4\")\n",
    "        self.pool3 = self.max_pool(self.conv3_4, 'pool3')\n",
    "\n",
    "        self.conv4_1 = self.conv_layer(self.pool3, 256, 512, \"conv4_1\")\n",
    "        self.conv4_2 = self.conv_layer(self.conv4_1, 512, 512, \"conv4_2\")\n",
    "        self.conv4_3 = self.conv_layer(self.conv4_2, 512, 512, \"conv4_3\")\n",
    "        self.conv4_4 = self.conv_layer(self.conv4_3, 512, 512, \"conv4_4\")\n",
    "        self.pool4 = self.max_pool(self.conv4_4, 'pool4')\n",
    "\n",
    "        self.conv5_1 = self.conv_layer(self.pool4, 512, 512, \"conv5_1\")\n",
    "        self.conv5_2 = self.conv_layer(self.conv5_1, 512, 512, \"conv5_2\")\n",
    "        self.conv5_3 = self.conv_layer(self.conv5_2, 512, 512, \"conv5_3\")\n",
    "        self.conv5_4 = self.conv_layer(self.conv5_3, 512, 512, \"conv5_4\")\n",
    "        self.pool5 = self.max_pool(self.conv5_4, 'pool5')\n",
    "\n",
    "        self.fc6 = self.fc_layer(self.pool5, 25088, 4096, \"fc6\")  # 25088 = ((224 / (2 ** 5)) ** 2) * 512\n",
    "        self.relu6 = tf.nn.relu(self.fc6)\n",
    "        if train_mode is not None:\n",
    "            self.relu6 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu6, 0.5), lambda: self.relu6)\n",
    "        elif self.trainable:\n",
    "            self.relu6 = tf.nn.dropout(self.relu6, 0.5)\n",
    "\n",
    "        self.fc7 = self.fc_layer(self.relu6, 4096, 4096, \"fc7\")\n",
    "        self.relu7 = tf.nn.relu(self.fc7)\n",
    "        if train_mode is not None:\n",
    "            self.relu7 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu7, 0.5), lambda: self.relu7)\n",
    "        elif self.trainable:\n",
    "            self.relu7 = tf.nn.dropout(self.relu7, 0.5)\n",
    "\n",
    "        self.fc8 = self.fc_layer(self.relu7, 4096, 1000, \"fc8\")\n",
    "\n",
    "        self.prob = tf.nn.softmax(self.fc8, name=\"prob\")\n",
    "\n",
    "        self.data_dict = None\n",
    "\n",
    "    def avg_pool(self, bottom, name):\n",
    "        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def max_pool(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def conv_layer(self, bottom, in_channels, out_channels, name):\n",
    "        with tf.variable_scope(name):\n",
    "            filt, conv_biases = self.get_conv_var(3, in_channels, out_channels, name)\n",
    "\n",
    "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "            relu = tf.nn.relu(bias)\n",
    "\n",
    "            return relu\n",
    "\n",
    "    def fc_layer(self, bottom, in_size, out_size, name):\n",
    "        with tf.variable_scope(name):\n",
    "            weights, biases = self.get_fc_var(in_size, out_size, name)\n",
    "\n",
    "            x = tf.reshape(bottom, [-1, in_size])\n",
    "            fc = tf.nn.bias_add(tf.matmul(x, weights), biases)\n",
    "\n",
    "            return fc\n",
    "\n",
    "    def get_conv_var(self, filter_size, in_channels, out_channels, name):\n",
    "        initial_value = tf.truncated_normal([filter_size, filter_size, in_channels, out_channels], 0.0, 0.001)\n",
    "        filters = self.get_var(initial_value, name, 0, name + \"_filters\")\n",
    "\n",
    "        initial_value = tf.truncated_normal([out_channels], .0, .001)\n",
    "        biases = self.get_var(initial_value, name, 1, name + \"_biases\")\n",
    "\n",
    "        return filters, biases\n",
    "\n",
    "    def get_fc_var(self, in_size, out_size, name):\n",
    "        initial_value = tf.truncated_normal([in_size, out_size], 0.0, 0.001)\n",
    "        weights = self.get_var(initial_value, name, 0, name + \"_weights\")\n",
    "\n",
    "        initial_value = tf.truncated_normal([out_size], .0, .001)\n",
    "        biases = self.get_var(initial_value, name, 1, name + \"_biases\")\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    def get_var(self, initial_value, name, idx, var_name):\n",
    "        if self.data_dict is not None and name in self.data_dict:\n",
    "            value = self.data_dict[name][idx]\n",
    "        else:\n",
    "            value = initial_value\n",
    "\n",
    "        if self.trainable:\n",
    "            var = tf.Variable(value, name=var_name)\n",
    "        else:\n",
    "            var = tf.constant(value, dtype=tf.float32, name=var_name)\n",
    "\n",
    "        self.var_dict[(name, idx)] = var\n",
    "\n",
    "        # print var_name, var.get_shape().as_list()\n",
    "        assert var.get_shape() == initial_value.get_shape()\n",
    "\n",
    "        return var\n",
    "\n",
    "    def save_npy(self, sess, npy_path=\"./vgg19-save.npy\"):\n",
    "        assert isinstance(sess, tf.Session)\n",
    "\n",
    "        data_dict = {}\n",
    "\n",
    "        for (name, idx), var in self.var_dict.items():\n",
    "            var_out = sess.run(var)\n",
    "            if not data_dict.has_key(name):\n",
    "                data_dict[name] = {}\n",
    "            data_dict[name][idx] = var_out\n",
    "\n",
    "        np.save(npy_path, data_dict)\n",
    "        print(\"file saved\", npy_path)\n",
    "        return npy_path\n",
    "\n",
    "    def get_var_count(self):\n",
    "        count = 0\n",
    "        for v in self.var_dict.values():\n",
    "            count += functools.reduce(lambda x, y: x * y, v.get_shape().as_list())\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import numpy as np\n",
    "\n",
    "# synset = [l.strip() for l in open('synset.txt').readlines()]\n",
    "\n",
    "# returns image of shape [224, 224, 3]\n",
    "# [height, width, depth]\n",
    "def load_image(path):\n",
    "    # load image\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    # print \"Original Image Shape: \", img.shape\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    # resize to 224, 224\n",
    "    resized_img = skimage.transform.resize(crop_img, (224, 224))\n",
    "    return resized_img\n",
    "\n",
    "\n",
    "# returns the top1 string\n",
    "def print_prob(prob, file_path):\n",
    "    synset = [l.strip() for l in open(file_path).readlines()]\n",
    "\n",
    "    # print prob\n",
    "    pred = np.argsort(prob)[::-1]\n",
    "\n",
    "    # Get top1 label\n",
    "    top1 = synset[pred[0]]\n",
    "    print(\"Top1: \", top1, prob[pred[0]])\n",
    "    # Get top5 label\n",
    "    top5 = [(synset[pred[i]], prob[pred[i]]) for i in range(5)]\n",
    "    print(\"Top5: \", top5)\n",
    "    return top1\n",
    "\n",
    "\n",
    "def load_image2(path, height=None, width=None):\n",
    "    # load image\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    if height is not None and width is not None:\n",
    "        ny = height\n",
    "        nx = width\n",
    "    elif height is not None:\n",
    "        ny = height\n",
    "        nx = img.shape[1] * ny / img.shape[0]\n",
    "    elif width is not None:\n",
    "        nx = width\n",
    "        ny = img.shape[0] * nx / img.shape[1]\n",
    "    else:\n",
    "        ny = img.shape[0]\n",
    "        nx = img.shape[1]\n",
    "    return skimage.transform.resize(img, (ny, nx))\n",
    "\n",
    "\n",
    "def test():\n",
    "    img = skimage.io.imread(\"./test_data/starry_night.jpg\")\n",
    "    ny = 300\n",
    "    nx = img.shape[1] * ny / img.shape[0]\n",
    "    img = skimage.transform.resize(img, (ny, nx))\n",
    "    skimage.io.imsave(\"./test_data/test/output.jpg\", img)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "    #test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143667240\n",
      "WARNING:tensorflow:From <ipython-input-5-1ca100b798d2>:29 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Top1:  n03014705 chest 0.340875\n",
      "Top5:  [('n03014705 chest', 0.34087518), ('n03127925 crate', 0.085570447), ('n03016953 chiffonier, commode', 0.053031586), ('n03125729 cradle', 0.040882848), ('n03131574 crib, cot', 0.040262647)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple tester for the vgg19_trainable\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#import vgg19_trainable as vgg19\n",
    "#import utils\n",
    "\n",
    "img1 = load_image(\"./mscoco/val2014/COCO_val2014_000000000133.jpg\")\n",
    "#img1 = load_image(\"./tiger.jpeg\")\n",
    "img1_true_result = [1 if i == 292 else 0 for i in range(1000)]  # 1-hot result for tiger\n",
    "\n",
    "batch1 = img1.reshape((1, 224, 224, 3))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sess = tf.Session()\n",
    "\n",
    "    images = tf.placeholder(tf.float32, [1, 224, 224, 3])\n",
    "    true_out = tf.placeholder(tf.float32, [1, 1000])\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "\n",
    "    vgg = Vgg19('./vgg19.npy')\n",
    "    vgg.build(images, train_mode)\n",
    "\n",
    "    # print number of variables used: 143667240 variables, i.e. ideal size = 548MB\n",
    "    print(vgg.get_var_count())\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # test classification\n",
    "    prob = sess.run(vgg.prob, feed_dict={images: batch1, train_mode: False})\n",
    "    print_prob(prob[0], './synset.txt')\n",
    "\n",
    "    # simple 1-step training\n",
    "    cost = tf.reduce_sum((vgg.prob - true_out) ** 2)\n",
    "    train = tf.train.GradientDescentOptimizer(0.0001).minimize(cost)\n",
    "    sess.run(train, feed_dict={images: batch1, true_out: [img1_true_result], train_mode: True})\n",
    "\n",
    "    # test classification again, should have a higher probability about tiger\n",
    "    prob = sess.run(vgg.prob, feed_dict={images: batch1, train_mode: False})\n",
    "    print_prob(prob[0], './synset.txt')\n",
    "\n",
    "    # test save\n",
    "    vgg.save_npy(sess, './test-save.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
