{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance\n",
    "import ui_script\n",
    "import pickle\n",
    "import random\n",
    "import demo\n",
    "w2v_dic = np.load('../../data/word2vec_train.npy')\n",
    "w2v_dic = w2v_dic[()]\n",
    "with open('../../data/caption_train.pkl','rb') as data_file:\n",
    "    caption_dic = pickle.load(data_file)\n",
    "with open('../../data/explanatory_words.pkl','rb') as data_file:\n",
    "    explanatory_words = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "w2v_model = gensim.models.Word2Vec.load_word2vec_format('../../data/GoogleNews-vectors-negative300.bin.gz',binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate a query image and caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".000000090777\n",
      ".000000391537\n",
      ".000000573988\n",
      ".000000082388\n",
      ".000000221618\n"
     ]
    }
   ],
   "source": [
    "# Random select query image and caption\n",
    "query_file_name = random.choice(list(w2v_dic.keys()))\n",
    "idx = random.randint(1,len(w2v_dic[query_file_name])) - 1\n",
    "query_w2v = w2v_dic[query_file_name][idx]\n",
    "query_caption = caption_dic[query_file_name][idx]\n",
    "\n",
    "# top 5 images\n",
    "top5_file_names = ['a', 'a', 'a', 'a', 'a']\n",
    "top5_captions = ['a', 'a', 'a', 'a', 'a']\n",
    "top5_distances = [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "top5_idx = [50, 50, 50, 50, 50]\n",
    "\n",
    "# Iterate over all images\n",
    "for file_name in w2v_dic.keys():\n",
    "    if file_name != query_file_name:\n",
    "        \n",
    "        # Iterate over all captions belonging to an image\n",
    "        closest_distance = 1.0\n",
    "        idx = -1\n",
    "        for i, w2v in enumerate(w2v_dic[file_name]):\n",
    "            dis = scipy.spatial.distance.cosine(query_w2v,w2v)\n",
    "            if dis < closest_distance:\n",
    "                closest_distance = dis\n",
    "                idx = i\n",
    "        \n",
    "        # See if closest caption is in top 5\n",
    "        for i, dis in enumerate(top5_distances):\n",
    "            if closest_distance < dis:\n",
    "                top5_distances[i] = closest_distance\n",
    "                top5_captions[i] = caption_dic[file_name][idx] + \"; \" + str(round(closest_distance, 4))\n",
    "                top5_file_names[i] = '../../data/train2014/' + file_name\n",
    "                top5_idx[i] = idx\n",
    "                break\n",
    "        \n",
    "# Find most similar word in word2vec\n",
    "aggregated_w2v = query_w2v\n",
    "for i in range(5):\n",
    "    aggregated_w2v += w2v_dic[top5_file_names[i][21:]][top5_idx[i]]\n",
    "most_similar_words = w2v_model.most_similar([aggregated_w2v],topn=3)\n",
    "\n",
    "# Display result\n",
    "file_names = ['../../data/train2014/' + query_file_name] + top5_file_names\n",
    "captions = [query_caption] + top5_captions\n",
    "show_top_5(file_names, captions, height = 250, title=str(most_similar_words)[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluate Explanatory words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words:\n",
      "('tennis', 4523.846276164055)\n",
      "('train', 3647.648230075836)\n",
      "('skateboard', 3410.3202080130577)\n",
      "('street', 3263.2962993383408)\n",
      "('bathroom', 3242.0992203354836)\n",
      "('white', 2891.0643061995506)\n",
      "('grass', 2659.8794860839844)\n",
      "('frisbee', 2532.1044417619705)\n",
      "('parked', 2525.205403506756)\n",
      "('sitting', 2465.619570374489)\n",
      "\n",
      "Length given cut-off:\n",
      "Cut-off: 100, #words: 439\n",
      "Cut-off: 300, #words: 177\n",
      "Cut-off: 500, #words: 119\n",
      "Cut-off: 700, #words: 86\n",
      "Cut-off: 1000, #words: 55\n",
      "Cut-off: 1300, #words: 39\n",
      "Cut-off: 1700, #words: 23\n",
      "Cut-off: 2000, #words: 19\n",
      "Cut-off: 2500, #words: 9\n",
      "\n",
      "Explanatory words given cut-off 700:\n",
      "['brown', 'street', 'parked', 'sign', 'walking', 'surf', 'beach', 'toilet', 'white', 'kitchen', 'bathroom', 'surfboard', 'bus', 'table', 'window', 'car', 'cat', 'train', 'bike', 'grass', 'game', 'laptop', 'hydrant', 'oven', 'tree', 'man', 'sidewalk', 'dog', 'stove', 'bench', 'kites', 'sky', 'boat', 'boy', 'bed', 'playing', 'frisbee', 'grassy', 'refrigerator', 'wearing', 'woman', 'skiing', 'Queues_spilled', 'skateboard', 'parking', 'couch', 'skate', 'bowl', 'wooden', 'motorcycle', 'snow', 'skis', 'teddy', 'sitting', 'road', 'fence', 'cake', 'truck', 'horses', 'airplane', 'plane', 'tennis', 'room', 'elephant', 'umbrellas', 'kite', 'horse', 'desk', 'vase', 'racket', 'ball', 'pizza', 'trees', 'eating', 'plate', 'luggage', 'giraffe', 'flying', 'tower', 'sandwich', 'elephants', 'bat', 'baseball', 'broccoli', 'giraffes', 'wii']\n"
     ]
    }
   ],
   "source": [
    "# Find top 10 words\n",
    "top_10 = [('hi',0)]*10\n",
    "for word in explanatory_words.items():\n",
    "    for i, item in enumerate(top_10):\n",
    "        if item[1] < word[1]:\n",
    "            top_10 =top_10[:i] + [word] + top_10[i:-1]\n",
    "            break\n",
    "print('Top 10 words:')\n",
    "for item in top_10:\n",
    "    print(item)\n",
    "print('')\n",
    "\n",
    "# Evaluate number of words given cut-off\n",
    "cut_offs = [100,300,500,700,1000,1300,1700,2000,2500]\n",
    "print('Length given cut-off:')\n",
    "for cut_off in cut_offs:\n",
    "    count = 0\n",
    "    for word in explanatory_words.items():\n",
    "        if word[1] > cut_off:\n",
    "            count += 1\n",
    "    print('Cut-off: ' + str(cut_off) + ', #words: ' + str(count))\n",
    "print('')\n",
    "\n",
    "# Given cut-off create list of word\n",
    "cut_off = 700\n",
    "words_cut_off = []\n",
    "for word in explanatory_words.items():\n",
    "    if word[1] > cut_off:\n",
    "        words_cut_off.append(word[0])\n",
    "print('Explanatory words given cut-off ' + str(cut_off) + ':')\n",
    "print(words_cut_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(demo)\n",
    "\n",
    "path_data = '../../data/val2014/'\n",
    "path_w2v = '../../data/image_space_20170302-1619.npy'\n",
    "path_explanatory = '../../data/explanatory_dic.npy'\n",
    "a = demo.demo(path_w2v, path_explanatory, path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy' has no attribute 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-af518d35b30b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy' has no attribute 'models'"
     ]
    }
   ],
   "source": [
    "scipy.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92307692,  0.03076923,  0.04615385])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "prob_dist = np.array([60, 2, 3])\n",
    "prob_dist/prob_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(60)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5]\n",
    "a[3:3] = [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 7, 4, 5]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 7, 4]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
