{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "#import regex as re\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import tensorflow as tf\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_caption(caption):\n",
    "    caption_splitted = re.split(\"[^a-zåàâäæçéèêëîïôöœßùûüÿA-ZÅÀÂÄÆÇÉÈÊËÎÏÔÖŒÙÛÜŸ’\\-]+\",caption)\n",
    "    caption_vector = np.array(300*[0])\n",
    "    for c in caption_splitted:\n",
    "#        caption_vector = np.sum([w2v[c] for c in caption_splitted])\n",
    "        try:\n",
    "            caption_vector = caption_vector + w2v[c]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return caption_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 40504\n",
      "{'license': 3, 'file_name': 'COCO_val2014_000000391895.jpg', 'coco_url': 'http://mscoco.org/images/391895', 'height': 360, 'width': 640, 'date_captured': '2013-11-14 11:18:45', 'flickr_url': 'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg', 'id': 391895}\n",
      "{'license': 4, 'file_name': 'COCO_val2014_000000522418.jpg', 'coco_url': 'http://mscoco.org/images/522418', 'height': 480, 'width': 640, 'date_captured': '2013-11-14 11:38:44', 'flickr_url': 'http://farm1.staticflickr.com/1/127244861_ab0c0381e7_z.jpg', 'id': 522418}\n",
      "{'license': 3, 'file_name': 'COCO_val2014_000000184613.jpg', 'coco_url': 'http://mscoco.org/images/184613', 'height': 336, 'width': 500, 'date_captured': '2013-11-14 12:36:29', 'flickr_url': 'http://farm3.staticflickr.com/2169/2118578392_1193aa04a0_z.jpg', 'id': 184613}\n",
      "\n",
      "Number of annotations: 202654\n",
      "{'image_id': 203564, 'id': 37, 'caption': 'A bicycle replica with a clock as the front wheel.'}\n",
      "{'image_id': 179765, 'id': 38, 'caption': 'A black Honda motorcycle parked in front of a garage.'}\n",
      "{'image_id': 322141, 'id': 49, 'caption': 'A room with blue walls and a white sink and door.'}\n"
     ]
    }
   ],
   "source": [
    "train_path = \"mscoco/captions_val2014.json\"\n",
    "with open(train_path, 'r') as train_file:\n",
    "    train_dict = json.load(train_file)\n",
    "    \n",
    "    print(\"Number of images: {}\".format(len(train_dict[\"images\"])))\n",
    "    for inst in train_dict[\"images\"][:3]:\n",
    "        print(inst)\n",
    "    print()\n",
    "    \n",
    "    print(\"Number of annotations: {}\".format(len(train_dict[\"annotations\"])))\n",
    "    for inst in train_dict[\"annotations\"][:3]:\n",
    "        print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Maybe have dict keys as strings\n",
    "own_dict = {}\n",
    "for im in train_dict[\"images\"]:\n",
    "    own_dict[im[\"id\"]] = {}\n",
    "    own_dict[im[\"id\"]][\"url\"] = im[\"flickr_url\"]\n",
    "for cap in train_dict[\"annotations\"]:\n",
    "    try:\n",
    "        own_dict[cap[\"image_id\"]][\"captions\"].append(cap[\"caption\"])\n",
    "    except KeyError:\n",
    "        own_dict[cap[\"image_id\"]][\"captions\"] = [cap[\"caption\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391895, {'url': 'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg', 'captions': ['A man with a red helmet on a small moped on a dirt road. ', 'Man riding a motor bike on a dirt road on the countryside.', 'A man riding on the back of a motorcycle.', 'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', 'A man in a red shirt and a red hat is on a motorcycle on a hill side.']})\n"
     ]
    }
   ],
   "source": [
    "len(own_dict)\n",
    "for a in own_dict.items():\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#word_set = set()\n",
    "#for inst in train_dict[\"annotations\"][:3]:\n",
    "#    word_set = word_set.union(re.split(\"[^a-zåàâäæçéèêëîïôöœßùûüÿA-ZÅÀÂÄÆÇÉÈÊËÎÏÔÖŒÙÛÜŸ’\\-]+\",inst[\"caption\"].lower()))\n",
    "#word_set.remove('')\n",
    "#print(word_set)\n",
    "\n",
    "from gensim import corpora\n",
    "documents = []\n",
    "for im in own_dict.values():\n",
    "    documents.extend(im[\"captions\"])\n",
    "documents = [d.lower() for d in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview structure of document list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202654\n",
      "['a man with a red helmet on a small moped on a dirt road. ', 'man riding a motor bike on a dirt road on the countryside.', 'a man riding on the back of a motorcycle.', 'a dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', 'a man in a red shirt and a red hat is on a motorcycle on a hill side.', 'a woman wearing a net on her head cutting a cake. ', 'a woman cutting a large white sheet cake.', 'a woman wearing a hair net cutting a large sheet cake.', 'there is a woman that is cutting a white cake', \"a woman marking a cake with the back of a chef's knife. \"]\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://farm4.staticflickr.com/3398/4630652911_38107d0cb9_z.jpg\n",
      "A fire hydrant is standing in the middle of a road.\n",
      "http://farm1.staticflickr.com/25/44927440_42e2e35a60_z.jpg\n",
      "A fire hydrant is standing in the middle of a parking lot.\n"
     ]
    }
   ],
   "source": [
    "query_image = random.choice(list(own_dict.keys()))\n",
    "# Use all captions for query image\n",
    "query_vector = sum_caption(own_dict[query_image][\"captions\"][1])\n",
    "curr_best = {\"im\":0, \"dist\":float(\"inf\"), \"cap_nr\":-1}\n",
    "for im in own_dict.items():\n",
    "    if im[0] != query_image:\n",
    "        for j in range(len(im[1][\"captions\"])):\n",
    "            temp_vector = sum_caption(own_dict[im[0]][\"captions\"][j])\n",
    "            if spatial.distance.cosine(query_vector,temp_vector) < curr_best[\"dist\"]:\n",
    "                curr_best[\"dist\"] = spatial.distance.cosine(query_vector,temp_vector)\n",
    "                curr_best[\"im\"] = im[0]\n",
    "                curr_best[\"cap_nr\"] = j\n",
    "                \n",
    "# Show images\n",
    "import webbrowser\n",
    "webbrowser.open_new(own_dict[query_image][\"url\"])\n",
    "webbrowser.open_new_tab(own_dict[curr_best[\"im\"]][\"url\"])\n",
    "print(own_dict[query_image][\"url\"])\n",
    "print(own_dict[query_image][\"captions\"][1])\n",
    "print(own_dict[curr_best[\"im\"]][\"url\"])\n",
    "print(own_dict[curr_best[\"im\"]][\"captions\"][curr_best[\"cap_nr\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}